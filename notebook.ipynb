{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My project for Optimization Course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate linear regression implemented through solving an optimization problem using the gradient descent method and some of its variants.\n",
    "\n",
    "The dataset used was taken from Kaggle.com and concerns house prices in the New York area. The idea is to perform a linear regression using the price as the dependent variable and the number of bedrooms, number of bathrooms, and the size of the house as independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"dataset/NY-House-Dataset.csv\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ELIMINO LE COLONNE NON DESIDERATE\n",
    "\n",
    "columns_to_drop = [\"ADDRESS\", \"STATE\", \"MAIN_ADDRESS\", \"ADMINISTRATIVE_AREA_LEVEL_2\", \n",
    "                   \"LOCALITY\", \"STREET_NAME\", \"LONG_NAME\", \"FORMATTED_ADDRESS\", \n",
    "                   \"LATITUDE\", \"LONGITUDE\",\"TYPE\",\"SUBLOCALITY\",\"BROKERTITLE\"]\n",
    "df_filtered = df.drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "#FILTRO GLI OUTLIER\n",
    "\n",
    "vars = [\"PRICE\", \"BEDS\", \"BATH\", \"PROPERTYSQFT\"]\n",
    "#df_filtered = df.copy()\n",
    "\n",
    "# Filtra i valori anomali utilizzando il concetto di IQR\n",
    "for var in vars:\n",
    "    Q1 = df_filtered[var].quantile(0.25)\n",
    "    Q3 = df_filtered[var].quantile(0.75)\n",
    "    \n",
    "    IQR = Q3 - Q1\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "    \n",
    "    df_filtered = df_filtered[(df_filtered[var] >= lower_limit) & (df_filtered[var] <= upper_limit)]\n",
    "    \n",
    "print(df_filtered.head)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression Model:\n",
    "\n",
    "$y = w_0 + w_1 x1 + w_2 x2 + w_3 x3$\n",
    "\n",
    "In this case:\n",
    "\n",
    "$PRICE = w_0 + w_1 BEDS + w_2 BATH + w_3 PROPERTYSQFT$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    \"\"\"Standardize the original data points (mean 0 and std dev 1).\"\"\"\n",
    "    x = x - np.mean(x)\n",
    "    x = x / np.std(x)\n",
    "    return x\n",
    "\n",
    "def build_model_data(x, y):\n",
    "    \"\"\"Get regression data in matrix form.\"\"\"\n",
    "    b = y\n",
    "    num_samples = len(b)\n",
    "    A = np.c_[np.ones(num_samples), x]\n",
    "    return A, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = df_filtered[['BEDS', 'BATH', 'PROPERTYSQFT']]\n",
    "prices = df_filtered['PRICE']\n",
    "print(features)\n",
    "print(prices)\n",
    "\n",
    "A, b = build_model_data(standardize(features), standardize(prices))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of samples n = ', b.shape[0])\n",
    "print('Dimension of each sample d = ', A.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Gradient descendent method functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_objective(Axmb):\n",
    "    obj = (Axmb**2).sum()\n",
    "    return obj\n",
    "\n",
    "def compute_gradient(A, x, b):\n",
    "    Axmb = A.dot(x) - b\n",
    "    grad = 2 * A.T.dot(Axmb)\n",
    "    return grad, Axmb\n",
    "\n",
    "def gradient_descent(A, initial_x, b, max_iters, gamma):\n",
    "    \"\"\"Gradient descent algorithm.\"\"\"\n",
    "    # Define parameters to store x and objective func. values\n",
    "    xs = [initial_x]\n",
    "    objectives = []\n",
    "    x = initial_x\n",
    "    for n_iter in range(max_iters):\n",
    "      \n",
    "        # compute objective and gradient\n",
    "        grad, Axmb = compute_gradient(A, x, b)\n",
    "        obj = calculate_objective(Axmb)\n",
    "\n",
    "        # ***************************************************\n",
    "        # YOUR CODE HERE\n",
    "        # update x by a gradient descent step\n",
    "        x = x - gamma * grad\n",
    "        # ***************************************************\n",
    "        \n",
    "        # store x and objective function value\n",
    "        xs.append(x)\n",
    "        objectives.append(obj)\n",
    "        print(\"Gradient Descent({bi}/{ti}): objective={l:.5f}, x=[{w0:.5f},{w1:.5f}]\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=obj, w0=x[0], w1=x[1]))\n",
    "\n",
    "    return objectives, xs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test Classic Gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_iters = 20\n",
    "gamma = 0.0000000001  \n",
    "x_initial = np.zeros(A.shape[1])\n",
    "\n",
    "# Start gradient descent.\n",
    "gradient_objectives_naive, gradient_xs_naive = gradient_descent(A, x_initial, b, max_iters, gamma)\n",
    "print(\"########################\")\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.xlabel('Number of steps')\n",
    "plt.ylabel('Objective Function')\n",
    "plt.plot(range(len(gradient_objectives_naive)), gradient_objectives_naive,'red', label='naive gradient descent')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try also to use a smoothness gradient descent with L parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_L(A, b):\n",
    "    \"\"\"Calculate the smoothness constant for f\"\"\"\n",
    "    # ***************************************************\n",
    "    # YOUR CODE HERE\n",
    "    # compute L = smoothness constant of f\n",
    "    L = 2 * np.linalg.norm(A.T.dot(A), ord=2)\n",
    "    # ***************************************************\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_iters = 20\n",
    "gamma_smooth = 1/calculate_L(A,b)\n",
    "print(gamma_smooth)\n",
    "x_initial = np.zeros(A.shape[1])\n",
    "\n",
    "# Start gradient descent.\n",
    "gradient_objectives_smooth, gradient_xs_smooth = gradient_descent(A, x_initial, b, max_iters, gamma_smooth)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.xlabel('Number of steps')\n",
    "plt.ylabel('Objective Function')\n",
    "plt.plot(range(len(gradient_objectives_smooth)), gradient_objectives_smooth,'green', label='gradient descent assuming smoothness')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
